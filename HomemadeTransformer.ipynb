{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Apple GPU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizerFast \n",
    "from scipy.stats import poisson\n",
    "\n",
    "dataset = pd.read_csv(\"clean_COVIDSenti.csv\")\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(tweet):\n",
    "    tokenized = tokenizer(tweet, return_tensors='pt', padding=\"max_length\", max_length = 47) #Max tweet token length is 47\n",
    "    return tokenized\n",
    "\n",
    "tweets, labels = dataset['tweet'], dataset['label'] + 1 #Labels need to be 0-indexed\n",
    "tokenized_tweets = tweets.map(tokenize)\n",
    "tokenized_tweets, labels = tokenized_tweets.to_list(), labels.to_list()\n",
    "vocab_size = max(map(lambda x: torch.max(x['input_ids']), tokenized_tweets))\n",
    "max_len = max(map(lambda x: len(x['input_ids']), tokenized_tweets))\n",
    "\n",
    "#Determining correct backend\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Training on Apple GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Training on CUDA\")\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    #Class used to encode positions\n",
    "    def __init__(self, embedding_dim, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_len, embedding_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-np.log(10000.0) / embedding_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe) #Ensures that this positional encoding isn't updated by the optimizer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe\n",
    "\n",
    "class SentimentTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, prelude_layers, poisson_mean, coda_layers,\n",
    "                 nhead = 4, dropout = 0.1, exit_threshold = 1e-4):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.prelude_layers = prelude_layers\n",
    "        self.coda_layers = coda_layers\n",
    "        self.poisson_mean = poisson_mean\n",
    "        self.exit_threshold = exit_threshold\n",
    "        \n",
    "        self.pe = PositionalEncoding(embedding_dim=embedding_dim, max_len=max_len)\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.prelude_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(embedding_dim, nhead = nhead, dropout=dropout, batch_first=True)\n",
    "            for _ in range(prelude_layers)\n",
    "        ])\n",
    "        \n",
    "        self.recurrent_layer = nn.TransformerEncoderLayer(embedding_dim, nhead=nhead, dropout=0.1, batch_first=True)\n",
    "\n",
    "        self.coda_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(embedding_dim, nhead = nhead, dropout=dropout, batch_first=True)\n",
    "            for _ in range(coda_layers)\n",
    "        ])\n",
    "        \n",
    "        self.lin = nn.Linear(embedding_dim, output_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        attention_mask = ~attention_mask.bool()\n",
    "        output = self.embedding(input_ids)\n",
    "        output = self.pe(output)\n",
    "        for layer in self.prelude_layers:\n",
    "            output = layer(output, src_key_padding_mask = attention_mask)\n",
    "        \n",
    "        prev_output = output\n",
    "        recurrences = poisson.rvs(self.poisson_mean, size = 1)\n",
    "        for _ in range(recurrences[0]):\n",
    "            output = self.recurrent_layer(output, src_key_padding_mask = attention_mask)\n",
    "            diff = torch.mean(torch.norm(output - prev_output, p=2, dim=-1))\n",
    "            if diff < self.exit_threshold:\n",
    "                # Early exit if the change is small enough\n",
    "                break\n",
    "            prev_output = output\n",
    "        \n",
    "        for layer in self.coda_layers:\n",
    "            output = layer(output, src_key_padding_mask = attention_mask)\n",
    "        \n",
    "        output = output.mean(axis = 1)\n",
    "        output = self.lin(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "Epoch 1\n",
      "Accuracies: tensor([0.4172, 0.9705, 0.0698], device='mps:0')\n",
      "New accuracy has been reached: 0.8105555772781372\n",
      "Epoch 2\n",
      "Accuracies: tensor([0.6564, 0.9293, 0.4357], device='mps:0')\n",
      "New accuracy has been reached: 0.8468888998031616\n",
      "Epoch 3\n",
      "Accuracies: tensor([0.7234, 0.9236, 0.4744], device='mps:0')\n",
      "New accuracy has been reached: 0.8568888902664185\n",
      "Epoch 4\n",
      "Accuracies: tensor([0.7769, 0.9214, 0.4837], device='mps:0')\n",
      "New accuracy has been reached: 0.8651111125946045\n",
      "Epoch 5\n",
      "Accuracies: tensor([0.7917, 0.9189, 0.5519], device='mps:0')\n",
      "New accuracy has been reached: 0.8706666827201843\n",
      "Epoch 6\n",
      "Accuracies: tensor([0.8098, 0.9102, 0.6031], device='mps:0')\n",
      "New accuracy has been reached: 0.870888888835907\n",
      "Epoch 7\n",
      "Accuracies: tensor([0.7872, 0.9250, 0.6264], device='mps:0')\n",
      "New accuracy has been reached: 0.8798888921737671\n",
      "Epoch 8\n",
      "Accuracies: tensor([0.8349, 0.9112, 0.6388], device='mps:0')\n",
      "Epoch 9\n",
      "Accuracies: tensor([0.8407, 0.9115, 0.6589], device='mps:0')\n",
      "New accuracy has been reached: 0.8812222480773926\n",
      "Epoch 10\n",
      "Accuracies: tensor([0.8356, 0.9092, 0.6744], device='mps:0')\n",
      "Epoch 11\n",
      "Accuracies: tensor([0.8646, 0.8977, 0.6961], device='mps:0')\n",
      "Epoch 12\n",
      "Accuracies: tensor([0.8536, 0.9077, 0.6884], device='mps:0')\n",
      "New accuracy has been reached: 0.8826666474342346\n",
      "Epoch 13\n",
      "Accuracies: tensor([0.8769, 0.9024, 0.6713], device='mps:0')\n",
      "Epoch 14\n",
      "Accuracies: tensor([0.8743, 0.9186, 0.6217], device='mps:0')\n",
      "New accuracy has been reached: 0.8896666765213013\n",
      "Epoch 15\n",
      "Accuracies: tensor([0.8652, 0.9280, 0.5891], device='mps:0')\n",
      "New accuracy has been reached: 0.8928889036178589\n",
      "Epoch 16\n",
      "Accuracies: tensor([0.8285, 0.9221, 0.6667], device='mps:0')\n",
      "Epoch 17\n",
      "Accuracies: tensor([0.8562, 0.9098, 0.6791], device='mps:0')\n",
      "Epoch 18\n",
      "Accuracies: tensor([0.8601, 0.9106, 0.6744], device='mps:0')\n",
      "Epoch 19\n",
      "Accuracies: tensor([0.8723, 0.9220, 0.5845], device='mps:0')\n",
      "Epoch 20\n",
      "Accuracies: tensor([0.8865, 0.9070, 0.6419], device='mps:0')\n",
      "FOR FOLD 0, THE TEST ACCURACY WAS 0.882111132144928\n",
      "FOR FOLD 0, THE ACCURACIES WERE tensor([0.8664, 0.9069, 0.6515], device='mps:0')\n",
      "---------------------------------------\n",
      "FOLD 1\n",
      "Epoch 1\n",
      "Accuracies: tensor([0.3646, 0.9766, 0.0000], device='mps:0')\n",
      "New accuracy has been reached: 0.7931110858917236\n",
      "Epoch 2\n",
      "Accuracies: tensor([0.6244, 0.9019, 0.4925], device='mps:0')\n",
      "New accuracy has been reached: 0.8212222456932068\n",
      "Epoch 3\n",
      "Accuracies: tensor([0.6648, 0.9085, 0.5479], device='mps:0')\n",
      "New accuracy has been reached: 0.8375555276870728\n",
      "Epoch 4\n",
      "Accuracies: tensor([0.7077, 0.9148, 0.5823], device='mps:0')\n",
      "New accuracy has been reached: 0.8525555729866028\n",
      "Epoch 5\n",
      "Accuracies: tensor([0.6863, 0.9267, 0.5853], device='mps:0')\n",
      "New accuracy has been reached: 0.8577777743339539\n",
      "Epoch 6\n",
      "Accuracies: tensor([0.7598, 0.9101, 0.6183], device='mps:0')\n",
      "New accuracy has been reached: 0.8612222075462341\n",
      "Epoch 7\n",
      "Accuracies: tensor([0.7763, 0.8993, 0.6407], device='mps:0')\n",
      "Epoch 8\n",
      "Accuracies: tensor([0.8033, 0.9093, 0.6287], device='mps:0')\n",
      "New accuracy has been reached: 0.8692222237586975\n",
      "Epoch 9\n",
      "Accuracies: tensor([0.7984, 0.9076, 0.6677], device='mps:0')\n",
      "New accuracy has been reached: 0.8700000047683716\n",
      "Epoch 10\n",
      "Accuracies: tensor([0.7623, 0.9258, 0.6437], device='mps:0')\n",
      "New accuracy has been reached: 0.8752222061157227\n",
      "Epoch 11\n",
      "Accuracies: tensor([0.7708, 0.9082, 0.7096], device='mps:0')\n",
      "Epoch 12\n",
      "Accuracies: tensor([0.8100, 0.9185, 0.6572], device='mps:0')\n",
      "New accuracy has been reached: 0.879444420337677\n",
      "Epoch 13\n",
      "Accuracies: tensor([0.8015, 0.9230, 0.6677], device='mps:0')\n",
      "New accuracy has been reached: 0.8820000290870667\n",
      "Epoch 14\n",
      "Accuracies: tensor([0.8388, 0.8918, 0.7081], device='mps:0')\n",
      "Epoch 15\n",
      "Accuracies: tensor([0.8370, 0.9196, 0.6452], device='mps:0')\n",
      "New accuracy has been reached: 0.8842222094535828\n",
      "Epoch 16\n",
      "Accuracies: tensor([0.7623, 0.9297, 0.6796], device='mps:0')\n",
      "Epoch 17\n",
      "Accuracies: tensor([0.8248, 0.9152, 0.6722], device='mps:0')\n",
      "Epoch 18\n",
      "Accuracies: tensor([0.7812, 0.9321, 0.6871], device='mps:0')\n",
      "New accuracy has been reached: 0.886555552482605\n",
      "Epoch 19\n",
      "Accuracies: tensor([0.8100, 0.9152, 0.6976], device='mps:0')\n",
      "Epoch 20\n",
      "Accuracies: tensor([0.7947, 0.9249, 0.6811], device='mps:0')\n",
      "Epoch 21\n",
      "Accuracies: tensor([0.8548, 0.8936, 0.6991], device='mps:0')\n",
      "Epoch 22\n",
      "Accuracies: tensor([0.7659, 0.8981, 0.7530], device='mps:0')\n",
      "Epoch 23\n",
      "Accuracies: tensor([0.8174, 0.9158, 0.6781], device='mps:0')\n",
      "FOR FOLD 1, THE TEST ACCURACY WAS 0.8861111402511597\n",
      "FOR FOLD 1, THE ACCURACIES WERE tensor([0.8284, 0.9198, 0.6864], device='mps:0')\n",
      "---------------------------------------\n",
      "FOLD 2\n",
      "Epoch 1\n",
      "Accuracies: tensor([0.4944, 0.9462, 0.2445], device='mps:0')\n",
      "New accuracy has been reached: 0.8154444694519043\n",
      "Epoch 2\n",
      "Accuracies: tensor([0.6290, 0.9296, 0.4826], device='mps:0')\n",
      "New accuracy has been reached: 0.843999981880188\n",
      "Epoch 3\n",
      "Accuracies: tensor([0.7679, 0.9059, 0.5379], device='mps:0')\n",
      "New accuracy has been reached: 0.8551111221313477\n",
      "Epoch 4\n",
      "Accuracies: tensor([0.7778, 0.9117, 0.5315], device='mps:0')\n",
      "New accuracy has been reached: 0.8607777953147888\n",
      "Epoch 5\n",
      "Accuracies: tensor([0.7735, 0.9280, 0.5710], device='mps:0')\n",
      "New accuracy has been reached: 0.875\n",
      "Epoch 6\n",
      "Accuracies: tensor([0.7975, 0.9248, 0.5473], device='mps:0')\n",
      "New accuracy has been reached: 0.875333309173584\n",
      "Epoch 7\n",
      "Accuracies: tensor([0.8247, 0.9182, 0.5789], device='mps:0')\n",
      "New accuracy has been reached: 0.8774444460868835\n",
      "Epoch 8\n",
      "Accuracies: tensor([0.8179, 0.9281, 0.6025], device='mps:0')\n",
      "New accuracy has been reached: 0.8853333592414856\n",
      "Epoch 9\n",
      "Accuracies: tensor([0.8364, 0.9185, 0.6388], device='mps:0')\n",
      "Epoch 10\n",
      "Accuracies: tensor([0.8352, 0.9257, 0.6372], device='mps:0')\n",
      "New accuracy has been reached: 0.8891111016273499\n",
      "Epoch 11\n",
      "Accuracies: tensor([0.8475, 0.9119, 0.6735], device='mps:0')\n",
      "Epoch 12\n",
      "Accuracies: tensor([0.8580, 0.9198, 0.6498], device='mps:0')\n",
      "New accuracy has been reached: 0.8896666765213013\n",
      "Epoch 13\n",
      "Accuracies: tensor([0.8630, 0.9234, 0.6593], device='mps:0')\n",
      "New accuracy has been reached: 0.8938888907432556\n",
      "Epoch 14\n",
      "Accuracies: tensor([0.8722, 0.9082, 0.6719], device='mps:0')\n",
      "Epoch 15\n",
      "Accuracies: tensor([0.8901, 0.8998, 0.6577], device='mps:0')\n",
      "Epoch 16\n",
      "Accuracies: tensor([0.8605, 0.9170, 0.6577], device='mps:0')\n",
      "Epoch 17\n",
      "Accuracies: tensor([0.8420, 0.9185, 0.6751], device='mps:0')\n",
      "Epoch 18\n",
      "Accuracies: tensor([0.8660, 0.8801, 0.7129], device='mps:0')\n",
      "FOR FOLD 2, THE TEST ACCURACY WAS 0.8657777905464172\n",
      "FOR FOLD 2, THE ACCURACIES WERE tensor([0.8659, 0.8802, 0.7226], device='mps:0')\n",
      "---------------------------------------\n",
      "FOLD 3\n",
      "Epoch 1\n",
      "Accuracies: tensor([0.5223, 0.9448, 0.1514], device='mps:0')\n",
      "New accuracy has been reached: 0.8148888945579529\n",
      "Epoch 2\n",
      "Accuracies: tensor([0.5534, 0.9414, 0.4210], device='mps:0')\n",
      "New accuracy has been reached: 0.8360000252723694\n",
      "Epoch 3\n",
      "Accuracies: tensor([0.6358, 0.9320, 0.4759], device='mps:0')\n",
      "New accuracy has been reached: 0.8475555777549744\n",
      "Epoch 4\n",
      "Accuracies: tensor([0.6852, 0.9192, 0.5707], device='mps:0')\n",
      "New accuracy has been reached: 0.8533333539962769\n",
      "Epoch 5\n",
      "Accuracies: tensor([0.7657, 0.9031, 0.6090], device='mps:0')\n",
      "New accuracy has been reached: 0.8584444522857666\n",
      "Epoch 6\n",
      "Accuracies: tensor([0.7901, 0.9132, 0.6057], device='mps:0')\n",
      "New accuracy has been reached: 0.8702222108840942\n",
      "Epoch 7\n",
      "Accuracies: tensor([0.8054, 0.9126, 0.6073], device='mps:0')\n",
      "New accuracy has been reached: 0.8726666569709778\n",
      "Epoch 8\n",
      "Accuracies: tensor([0.8023, 0.9118, 0.6456], device='mps:0')\n",
      "New accuracy has been reached: 0.8741111159324646\n",
      "Epoch 9\n",
      "Accuracies: tensor([0.8121, 0.8962, 0.6622], device='mps:0')\n",
      "Epoch 10\n",
      "Accuracies: tensor([0.8115, 0.9186, 0.6306], device='mps:0')\n",
      "New accuracy has been reached: 0.8798888921737671\n",
      "Epoch 11\n",
      "Accuracies: tensor([0.7919, 0.9238, 0.6339], device='mps:0')\n",
      "New accuracy has been reached: 0.8804444670677185\n",
      "Epoch 12\n",
      "Accuracies: tensor([0.8176, 0.9078, 0.6722], device='mps:0')\n",
      "Epoch 13\n",
      "Accuracies: tensor([0.7749, 0.9173, 0.6789], device='mps:0')\n",
      "Epoch 14\n",
      "Accuracies: tensor([0.8438, 0.9022, 0.6822], device='mps:0')\n",
      "Epoch 15\n",
      "Accuracies: tensor([0.8072, 0.9194, 0.6522], device='mps:0')\n",
      "New accuracy has been reached: 0.8811110854148865\n",
      "Epoch 16\n",
      "Accuracies: tensor([0.8462, 0.9053, 0.6456], device='mps:0')\n",
      "Epoch 17\n",
      "Accuracies: tensor([0.8481, 0.9025, 0.6839], device='mps:0')\n",
      "Epoch 18\n",
      "Accuracies: tensor([0.8292, 0.9149, 0.6739], device='mps:0')\n",
      "New accuracy has been reached: 0.883222222328186\n",
      "Epoch 19\n",
      "Accuracies: tensor([0.8194, 0.9188, 0.6722], device='mps:0')\n",
      "New accuracy has been reached: 0.8842222094535828\n",
      "Epoch 20\n",
      "Accuracies: tensor([0.8487, 0.8984, 0.6789], device='mps:0')\n",
      "Epoch 21\n",
      "Accuracies: tensor([0.8340, 0.9112, 0.6606], device='mps:0')\n",
      "Epoch 22\n",
      "Accuracies: tensor([0.8359, 0.9149, 0.6905], device='mps:0')\n",
      "New accuracy has been reached: 0.8855555653572083\n",
      "Epoch 23\n",
      "Accuracies: tensor([0.8377, 0.9037, 0.7055], device='mps:0')\n",
      "Epoch 24\n",
      "Accuracies: tensor([0.8456, 0.9142, 0.6639], device='mps:0')\n",
      "Epoch 25\n",
      "Accuracies: tensor([0.8286, 0.9086, 0.6822], device='mps:0')\n",
      "Epoch 26\n",
      "Accuracies: tensor([0.8450, 0.9072, 0.6755], device='mps:0')\n",
      "Epoch 27\n",
      "Accuracies: tensor([0.8066, 0.9143, 0.6855], device='mps:0')\n",
      "FOR FOLD 3, THE TEST ACCURACY WAS 0.883222222328186\n",
      "FOR FOLD 3, THE ACCURACIES WERE tensor([0.8224, 0.9149, 0.7110], device='mps:0')\n",
      "---------------------------------------\n",
      "FOLD 4\n",
      "Epoch 1\n",
      "Accuracies: tensor([0.3862, 0.9731, 0.0000], device='mps:0')\n",
      "New accuracy has been reached: 0.793666660785675\n",
      "Epoch 2\n",
      "Accuracies: tensor([0.6301, 0.9258, 0.4585], device='mps:0')\n",
      "New accuracy has been reached: 0.8371111154556274\n",
      "Epoch 3\n",
      "Accuracies: tensor([0.6295, 0.9339, 0.5128], device='mps:0')\n",
      "New accuracy has been reached: 0.847000002861023\n",
      "Epoch 4\n",
      "Accuracies: tensor([0.6459, 0.9219, 0.6229], device='mps:0')\n",
      "New accuracy has been reached: 0.8492222428321838\n",
      "Epoch 5\n",
      "Accuracies: tensor([0.6695, 0.9351, 0.5837], device='mps:0')\n",
      "New accuracy has been reached: 0.8604444265365601\n",
      "Epoch 6\n",
      "Accuracies: tensor([0.7609, 0.9279, 0.5867], device='mps:0')\n",
      "New accuracy has been reached: 0.8721110820770264\n",
      "Epoch 7\n",
      "Accuracies: tensor([0.7349, 0.9376, 0.5882], device='mps:0')\n",
      "New accuracy has been reached: 0.874666690826416\n",
      "Epoch 8\n",
      "Accuracies: tensor([0.7615, 0.9336, 0.6078], device='mps:0')\n",
      "New accuracy has been reached: 0.878000020980835\n",
      "Epoch 9\n",
      "Accuracies: tensor([0.7561, 0.9283, 0.6576], device='mps:0')\n",
      "Epoch 10\n",
      "Accuracies: tensor([0.7688, 0.9400, 0.5913], device='mps:0')\n",
      "New accuracy has been reached: 0.882888913154602\n",
      "Epoch 11\n",
      "Accuracies: tensor([0.7960, 0.9261, 0.6546], device='mps:0')\n",
      "Epoch 12\n",
      "Accuracies: tensor([0.7742, 0.9373, 0.6471], device='mps:0')\n",
      "New accuracy has been reached: 0.8859999775886536\n",
      "Epoch 13\n",
      "Accuracies: tensor([0.7373, 0.9400, 0.6124], device='mps:0')\n",
      "Epoch 14\n",
      "Accuracies: tensor([0.7597, 0.9327, 0.6833], device='mps:0')\n",
      "Epoch 15\n",
      "Accuracies: tensor([0.7863, 0.9318, 0.6893], device='mps:0')\n",
      "New accuracy has been reached: 0.8872222304344177\n",
      "Epoch 16\n",
      "Accuracies: tensor([0.7785, 0.9258, 0.7029], device='mps:0')\n",
      "Epoch 17\n",
      "Accuracies: tensor([0.6955, 0.9484, 0.6667], device='mps:0')\n",
      "Epoch 18\n",
      "Accuracies: tensor([0.7288, 0.9447, 0.6576], device='mps:0')\n",
      "Epoch 19\n",
      "Accuracies: tensor([0.7906, 0.9399, 0.6410], device='mps:0')\n",
      "New accuracy has been reached: 0.8904444575309753\n",
      "Epoch 20\n",
      "Accuracies: tensor([0.7597, 0.9433, 0.6320], device='mps:0')\n",
      "Epoch 21\n",
      "Accuracies: tensor([0.7343, 0.9488, 0.6320], device='mps:0')\n",
      "Epoch 22\n",
      "Accuracies: tensor([0.7094, 0.9300, 0.7255], device='mps:0')\n",
      "Epoch 23\n",
      "Accuracies: tensor([0.7125, 0.9436, 0.6817], device='mps:0')\n",
      "Epoch 24\n",
      "Accuracies: tensor([0.7058, 0.9445, 0.6983], device='mps:0')\n",
      "FOR FOLD 4, THE TEST ACCURACY WAS 0.8836666941642761\n",
      "FOR FOLD 4, THE ACCURACIES WERE tensor([0.7105, 0.9468, 0.6569], device='mps:0')\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler, Dataset, random_split\n",
    "\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, tweets, labels):\n",
    "        self.x = tweets\n",
    "        self.y = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Check that x is really a dictionary before processing\n",
    "        x = self.x[index]\n",
    "        x = dict(x)\n",
    "        x = {key: torch.squeeze(val, dim = 0) for key, val in x.items()}\n",
    "        y = self.y[index]\n",
    "        return (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "folds = 5\n",
    "early_stopping = 5 #Stop if 5 epochs without improvement on val\n",
    "train_frac = 0.8\n",
    "test_frac = 0.1\n",
    "val_frac = 0.1\n",
    "batch_size = 64\n",
    "test_accuracies = []\n",
    "data = TweetDataset(tokenized_tweets, labels)\n",
    "\n",
    "#Instantiating model\n",
    "dropout = 0.5\n",
    "nhead = 8\n",
    "output_size = 3\n",
    "embedding_dim = 128\n",
    "prelude_layers = 1\n",
    "coda_layers = 1\n",
    "poisson_mean = 3\n",
    "\n",
    "for fold in range(folds):\n",
    "    \n",
    "    model = SentimentTransformer(\n",
    "    vocab_size=vocab_size, \n",
    "    output_size=output_size, \n",
    "    embedding_dim=embedding_dim, \n",
    "    prelude_layers=prelude_layers, \n",
    "    coda_layers=coda_layers, \n",
    "    poisson_mean=poisson_mean,\n",
    "    nhead = nhead, \n",
    "    dropout = dropout)\n",
    "    \n",
    "    print(f\"FOLD {fold}\")\n",
    "    gen = torch.Generator().manual_seed(fold)\n",
    "    train, val, test = random_split(data, lengths=[train_frac, val_frac, test_frac], generator=gen)\n",
    "    \n",
    "    #Dealing with imbalanced class weights for train dataset\n",
    "    labels_for_counts = list(map(lambda x: x[-1], train))\n",
    "    frequency = 1 / np.bincount(labels_for_counts)\n",
    "    class_weights = torch.tensor(frequency, dtype=torch.float32)\n",
    "    obs_weights = list(map(lambda x: class_weights[x[-1]], train))\n",
    "        \n",
    "    train_sampler = WeightedRandomSampler(weights = obs_weights, num_samples = len(obs_weights))\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle = True) #Test with shuffle instead of sampler, maybe?\n",
    "    val_loader = DataLoader(val, shuffle=False, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test, shuffle=False, batch_size=batch_size)\n",
    "    \n",
    "    #---- TRAINING ACTUAL MODEL FROM HERE ON OUT ----#\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    lr = 0.0001\n",
    "    epoch = 0\n",
    "    no_improvement = 0\n",
    "    curr_acc = 0\n",
    "    criterion = nn.CrossEntropyLoss() #Without softmax we use CEL\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = lr)\n",
    "\n",
    "    while no_improvement < early_stopping:\n",
    "        epoch += 1\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        \n",
    "        #Training model layers\n",
    "        for train_inputs, train_labels in train_loader:\n",
    "            train_inputs['input_ids'], train_inputs['attention_mask'] = train_inputs['input_ids'].to(device), train_inputs['attention_mask'].to(device)\n",
    "            train_labels = train_labels.to(device)\n",
    "            \n",
    "            model.zero_grad()\n",
    "            with torch.autocast(\"mps\"):\n",
    "                output = model(**train_inputs)   \n",
    "            loss = criterion(output, train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        #Early stopping\n",
    "        model.eval()\n",
    "        correct = torch.tensor(0, device = device)\n",
    "        incorrect = torch.tensor(0, device = device)\n",
    "        corrects = torch.zeros(3, device = device)\n",
    "        incorrects = torch.zeros(3, device = device)\n",
    "        \n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_inputs['input_ids'], val_inputs['attention_mask'] = val_inputs['input_ids'].to(device), val_inputs['attention_mask'].to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            probs = model(**val_inputs)\n",
    "            preds = torch.argmax(probs, axis = 1)\n",
    "            preds = preds.to(device)\n",
    "            correct += (preds == val_labels).sum()\n",
    "            incorrect += (preds != val_labels).sum()  \n",
    "            for idx in range(3):\n",
    "                corrects[idx] += ((preds == val_labels) & (val_labels == idx)).sum() \n",
    "                incorrects[idx] += ((preds != val_labels) & (val_labels == idx)).sum() \n",
    "        \n",
    "        accuracy = correct / (correct + incorrect)\n",
    "        val_accuracy_each = corrects / (corrects + incorrects)\n",
    "        print(f\"Accuracies: {val_accuracy_each}\")\n",
    "        if accuracy > curr_acc:\n",
    "            \n",
    "            print(f\"New accuracy has been reached: {accuracy}\")\n",
    "            curr_acc = accuracy\n",
    "            no_improvement = 0\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "    model.eval()\n",
    "    corrects = torch.zeros(3, device = device)\n",
    "    incorrects = torch.zeros(3, device = device)\n",
    "    \n",
    "    correct = torch.tensor(0, device = device)\n",
    "    incorrect = torch.tensor(0, device = device)\n",
    "    \n",
    "    #Getting test accuracy for CV purposes\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_inputs['input_ids'], test_inputs['attention_mask'] = test_inputs['input_ids'].to(device), test_inputs['attention_mask'].to(device)\n",
    "        test_labels = test_labels.to(device)\n",
    "        probs = model(**test_inputs)\n",
    "        preds = torch.argmax(probs, axis = 1)\n",
    "        preds = preds.to(device)\n",
    "        correct += (preds == test_labels).sum()\n",
    "        incorrect += (preds != test_labels).sum()  \n",
    "        for idx in range(3):\n",
    "            corrects[idx] += ((preds == test_labels) & (test_labels == idx)).sum() \n",
    "            incorrects[idx] += ((preds != test_labels) & (test_labels == idx)).sum() \n",
    "    \n",
    "    test_accuracy = correct / (correct + incorrect)\n",
    "    test_accuracy_each = corrects / (corrects + incorrects)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f\"FOR FOLD {fold}, THE TEST ACCURACY WAS {test_accuracy}\")\n",
    "    print(f\"FOR FOLD {fold}, THE ACCURACIES WERE {test_accuracy_each}\")\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for _ in range(poisson.rvs(2)):\n",
    "    print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
